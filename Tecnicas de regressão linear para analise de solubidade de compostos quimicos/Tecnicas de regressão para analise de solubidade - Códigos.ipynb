{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, KFold, GridSearchCV, cross_val_predict\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test datasets\n",
    "solTestX = pd.read_csv(\"solubility/solTestX.txt\",delimiter=\"\\t\") #Test set\n",
    "solTestXtrans = pd.read_csv(\"solubility/solTestXtrans.txt\",delimiter=\"\\t\")#Test set predictors after the same transformations used on the training set are applied.\n",
    "solTestY = pd.read_csv(\"solubility/solTestY.txt\",delimiter=\"\\t\") #Test set - solubility values for each compound\n",
    "\n",
    "# Train datasets\n",
    "solTrainX = pd.read_csv(\"solubility/solTrainX.txt\",delimiter=\"\\t\") #Train set\n",
    "solTrainXtrans = pd.read_csv(\"solubility/solTrainXtrans.txt\",delimiter=\"\\t\") #Training set predictors after transformations for skewness and centering/scaling.\n",
    "solTrainY = pd.read_csv(\"solubility/solTrainY.txt\",delimiter=\"\\t\") #Train set - solubility values for each compound\n",
    "\n",
    "solTrainXtrans.index = range(1, len(solTrainXtrans) + 1) #Get dataset indexes starting from 1\n",
    "solTrainX.index = range(0, len(solTrainX)) #Get dataset indexes starting from 0\n",
    "solTestX.index = range(0, len(solTestX)) #Get dataset indexes starting from 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_predictors = [\"MolWeight\", \"NumAtoms\", \"NumNonHAtoms\", \"NumBonds\", \"NumNonHBonds\", \"NumMultBonds\", \"NumRotBonds\", \"NumDblBonds\", \"NumAromaticBonds\", \"NumHydrogen\", \"NumCarbon\", \"NumNitrogen\", \"NumOxygen\", \"NumSulfer\", \"NumChlorine\", \"NumHalogen\", \"NumRings\", \"HydrophilicFactor\", \"SurfaceArea1\", \"SurfaceArea2\", \"x\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis and pre-procesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XYTrain = solTrainXtrans.join(solTrainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete dataset\n",
    "dataset = pd.concat([solTrainXtrans[continuous_predictors[:-1]], solTestXtrans[continuous_predictors[:-1]]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset transformed with Yeo-jonhson\n",
    "pt = PowerTransformer()\n",
    "pt.fit(dataset)\n",
    "PowerTransformer(copy=True, method='yeo-johnson', standardize=True)\n",
    "totalXtrans = pd.DataFrame(pt.transform(dataset), columns=continuous_predictors[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.skew().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given transformed dataset with box-cox\n",
    "dataset_analysis = {\n",
    "    'Min': dataset.min(),\n",
    "    'Max': dataset.max(),\n",
    "    'Mean': dataset.mean(),\n",
    "    'Std': dataset.std(),\n",
    "    'Skewness': dataset.skew()\n",
    "}\n",
    "df = pd.DataFrame(dataset_analysis)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset transformed with Yeo-jonhson\n",
    "\n",
    "pt = PowerTransformer(method='yeo-johnson', standardize=True, copy=True).fit(dataset[continuous_predictors[:-1]])\n",
    "\n",
    "dataset_trans = pd.DataFrame(pt.transform(dataset[continuous_predictors[:-1]]))\n",
    "Xtrain = solTrainX.iloc[:,:208].join(pd.DataFrame(pt.transform(solTrainX[continuous_predictors[:-1]]), columns=continuous_predictors[:-1]))\n",
    "Xtest = solTestX.iloc[:,:208].join(pd.DataFrame(pt.transform(solTestX[continuous_predictors[:-1]]), columns=continuous_predictors[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset transformed with Yeo-jonhson\n",
    "dataset_analysis = {\n",
    "    'Min': dataset_trans.min(),\n",
    "    'Max': dataset_trans.max(),\n",
    "    'Mean': dataset_trans.mean(),\n",
    "    'Std': dataset_trans.std(),\n",
    "    'Skewness': dataset_trans.skew()\n",
    "}\n",
    "\n",
    "df2 = pd.DataFrame(dataset_analysis)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in continuous_predictors[:-1]:\n",
    "    sns.lmplot(x=x, y=\"x\", data=XYTrain)    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solTrainXcontinous = solTrainXtrans.iloc[:,208:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = XYTrain[continuous_predictors[:-1]].corr()\n",
    "mask = np.zeros_like(corr)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(18, 12))\n",
    "\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    linewidths=.5,\n",
    "    ax=ax, \n",
    "    vmin=-1, vmax=1, \n",
    "    cmap=\"viridis\",\n",
    "    cbar_kws={\"shrink\": .7}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = XYTrain[continuous_predictors].corr()\n",
    "mask = np.zeros_like(corr)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(18, 12))\n",
    "\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    linewidths=.5,\n",
    "    ax=ax, \n",
    "    vmin=-1, vmax=1, \n",
    "    cmap=\"viridis\",\n",
    "    cbar_kws={\"shrink\": .7}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oridnary linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "model = lm.fit(solTrainXtrans, solTrainY)\n",
    "Ypred = model.predict(solTestXtrans)\n",
    "\n",
    "print('RMSE', np.sqrt(mean_squared_error(solTestY, Ypred)))\n",
    "print('R2', r2_score(solTestY, Ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "MSEs = cross_val_score(lm, solTrainXtrans, solTrainY, scoring='neg_mean_squared_error', cv=10)\n",
    "mean_MSE = np.mean(np.abs(MSEs))\n",
    "print(np.sqrt(mean_MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, random_state=100, shuffle=True)\n",
    "\n",
    "R2 = []\n",
    "RMSE = []\n",
    "\n",
    "for train_index, test_index in kf.split(solTrainXtrans):\n",
    "    x_train = solTrainXtrans.iloc[train_index]\n",
    "    y_train = solTrainY.iloc[train_index]\n",
    "    \n",
    "    x_test = solTrainXtrans.iloc[test_index]\n",
    "    y_test = solTrainY.iloc[test_index]\n",
    "    \n",
    "    lm = LinearRegression()\n",
    "    lm.fit(x_train, y_train)\n",
    "    \n",
    "    preds = lm.predict(x_test)\n",
    "    \n",
    "    RMSE.append(np.sqrt(mean_squared_error(y_test, preds)))\n",
    "    R2.append(r2_score(y_test, preds))\n",
    "\n",
    "print('RMSE', np.mean(RMSE))\n",
    "print('R2', np.mean(R2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLR Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypred_ = sum(Ypred.tolist(), [])\n",
    "solTestY_ = sum(solTestY.values.tolist(), [])\n",
    "resid = [y_test - y_pred for y_test, y_pred in zip(solTestY_, Ypred_)]\n",
    "\n",
    "df1 = pd.DataFrame({'Prediction':Ypred_, 'Observation':solTestY_})\n",
    "sns.lmplot(x='Prediction', y=\"Observation\", data=df1, fit_reg=False)\n",
    "\n",
    "df2 = pd.DataFrame({'Prediction': Ypred_, 'Residue': resid})\n",
    "sns.lmplot(x='Prediction', y=\"Residue\", data=df2, fit_reg=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing high correlated predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = solTrainX.corr().abs()\n",
    "\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.90)]\n",
    "\n",
    "newX = solTrainX.drop(to_drop, axis=1)\n",
    "newXtest = solTestX.drop(to_drop, axis=1)\n",
    "print(to_drop)\n",
    "\n",
    "model2 = LinearRegression().fit(newX, solTrainY)\n",
    "Ypred2 = model2.predict(newXtest)\n",
    "\n",
    "print('RMSE', np.sqrt(mean_squared_error(solTestY, Ypred2)))\n",
    "print('R2', r2_score(solTestY, Ypred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Penalized linear regression model L2 (Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(solTrainXtrans, solTrainY)\n",
    "\n",
    "rr = Ridge(alpha=0.03)\n",
    "rr.fit(solTrainXtrans, solTrainY)\n",
    "\n",
    "rr3 = Ridge(alpha=100)\n",
    "rr3.fit(solTrainXtrans, solTrainY)\n",
    "\n",
    "plt.plot(range(209, 229), rr.coef_[0][208:],alpha=0.7,linestyle='none',marker='X',markersize=9,color='red',label=r'Ridge; $\\alpha = 0.01$',zorder=7) # zorder for ordering the markers\n",
    "plt.plot(range(209, 229), rr3.coef_[0][208:],alpha=0.5,linestyle='none',marker='s',markersize=9,color='blue',label=r'Ridge; $\\alpha = 100$') # alpha here is for transparency\n",
    "plt.plot(range(209, 229), lr.coef_[0][208:],alpha=0.4,linestyle='none',marker='o',markersize=9,color='green',label='Linear Regression')\n",
    "\n",
    "plt.xlabel('Índice Coeficiente',fontsize=14)\n",
    "plt.ylabel('Magnitude do coeficiente',fontsize=14)\n",
    "plt.legend(fontsize=12,loc=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge()\n",
    "params = {'alpha': np.linspace(0.1, 15,100)}\n",
    "ridge_regressor = GridSearchCV(ridge, params, scoring=('r2', 'neg_mean_squared_error'), cv=10, refit='neg_mean_squared_error')\n",
    "ridge_regressor.fit(solTrainXtrans, solTrainY)\n",
    "\n",
    "print(ridge_regressor.best_params_)\n",
    "print(np.sqrt(np.abs(ridge_regressor.best_score_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.linspace(1,20,30)\n",
    "cv_ridge = [np.sqrt(-cross_val_score(Ridge(alpha = alpha), solTrainXtrans, solTrainY, scoring=\"neg_mean_squared_error\", cv = 10)).mean() for alpha in alphas]\n",
    "cv_ridge = pd.Series(cv_ridge, index = alphas)\n",
    "cv_ridge.plot(title = \"Validation\")\n",
    "\n",
    "alpha_min = alphas[cv_ridge.tolist().index(cv_ridge.min())]\n",
    "\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.plot(alpha_min, cv_ridge.min(), marker='o', markersize=9, color='red')\n",
    "plt.show()\n",
    "print(alpha_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.linspace(1,20,30)\n",
    "R2 = []\n",
    "RMSE = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    rr = RidgeCV(alphas=[alpha], cv=10) \n",
    "    rmodel = rr.fit(solTrainXtrans, solTrainY)\n",
    "    Ypred = rmodel.predict(solTestXtrans)\n",
    "    \n",
    "    R2.append(r2_score(solTestY, Ypred))\n",
    "    RMSE.append(np.sqrt(mean_squared_error(solTestY, Ypred)))\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'alpha': alphas,\n",
    "        'RMSE': RMSE,\n",
    "        'R2': R2\n",
    "    }\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parcial Least Squares regression (PLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = range(1,30)\n",
    "\n",
    "cv_pls = [np.sqrt(-cross_val_score(PLSRegression(n_components=comps), solTrainXtrans, solTrainY, scoring='neg_mean_squared_error', cv=10)).mean() for comps in components]\n",
    "cv_pls = pd.Series(cv_pls, index = components)\n",
    "\n",
    "cv_pls.plot(title='Validation')\n",
    "\n",
    "n_comp_min = components[cv_pls.tolist().index(cv_pls.min())]\n",
    "\n",
    "print(n_comp_min, cv_pls.min())\n",
    "\n",
    "plt.xlabel(\"components\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.plot(n_comp_min, cv_pls.min(), marker='o', markersize=9, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pls = PLSRegression(n_components = 19)\n",
    "\n",
    "pls.fit(solTrainXtrans, solTrainY)\n",
    "Ypred_pls = pls.predict(solTestXtrans)\n",
    "Ytest_pls = solTestY\n",
    "\n",
    "score = r2_score(Ytest_pls, Ypred_pls)\n",
    "rmse = np.sqrt(mean_squared_error(Ytest_pls, Ypred_pls))\n",
    "\n",
    "print('R2', score)\n",
    "print('RMSE', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypred_ = sum(Ypred_pls.tolist(), [])\n",
    "Ytest_ = sum(Ytest_pls.values.tolist(), [])\n",
    "resid = [y_test - ypred for y_test, ypred in zip(Ytest_, Ypred_)]\n",
    "\n",
    "df1 = pd.DataFrame({'Prediction': Ypred_, 'Observation': Ytest_})\n",
    "sns.lmplot(x='Prediction', y=\"Observation\", data=df1, fit_reg=False)\n",
    "\n",
    "df2 = pd.DataFrame({'Prediction': Ypred_, 'Residue': resid})\n",
    "sns.lmplot(x='Prediction', y=\"Residue\", data=df2, fit_reg=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
